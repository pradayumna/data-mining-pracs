{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-DaMSaMbskG"
   },
   "source": [
    "# Practical B Data Preparation\n",
    "In this practial we will be preparing data for use with some data mining applications.\n",
    "\n",
    "Similar to last week we will be using Jupyter Notebooks, Google Collab, and Python/Pandas. The data for this week can be found on [GitHub](https://github.com/PaulHancock/COMP5009_pracs).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqWJd87HcgLF"
   },
   "source": [
    "## Q3 from Chapter 2 of [Aggarwal](https://www.springer.com/gp/book/9783319141411)\n",
    "\n",
    "We will be working with the Arrythmia data set from the UCI Machine Learning Repository at http://archive.ics.uci.edu/ml/datasets/arrhythmia. The data are available via github as [arrhythmia.data.with.header.csv](https://github.com/PaulHancock/COMP5009_pracs/blob/main/data/arrhythmia.data.with.header.csv)\n",
    "\n",
    "Use Pandas to load the data and complete the following tasks: \n",
    "1. Load the data into a pandas data frame, converting '?' into `NaN`\n",
    "\n",
    "1. Modify the values of the class attribute att280 as follows: \n",
    "\n",
    "  a. Convert value 1 to N \n",
    "\n",
    "  b. Convert value 16 to O \n",
    "\n",
    "  c. Convert other values to A \n",
    "\n",
    "1. Find and remove all attributes with more than 80% missing values.\n",
    "\n",
    "1. Find all attributes with less than 5% missing values and replace these missing values with either the mean or the mode of the attribute.  \n",
    "\n",
    "1. Discretize attributes att3 and att4 into 10 equi-width ranges and 10 equi-depth ranges respectively. \n",
    "\n",
    "1. Examine and comment on the intervals in each case. \n",
    "\n",
    "1. Standardize all numeric attributes to a mean of 0 and a standard deviation of 1. \n",
    "\n",
    "1. Detect all duplicate rows and remove them if found. \n",
    "\n",
    "1. Randomly sample 100 instances and save them as `test.csv`. Save the remaining instances as `train.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xl36oq-AesTg"
   },
   "source": [
    "### Load the data\n",
    "Load the data into a pandas data frame, converting '?' into `NaN`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWmUd1v4Klom"
   },
   "source": [
    "Look at last week's prac and load the data into our data frame.\n",
    "\n",
    "The link to the data file should be: https://raw.githubusercontent.com/PaulHancock/COMP5009_pracs/main/data/arrhythmia.data.with.header.csv\n",
    "\n",
    "The difference here is that the csv file uses '?' to indicate missing values. This is annoying but pandas has a workaround.\n",
    "Look at the help for the `pd.read_csv` to see what parameter you might use to indicate that '?' should be interpreted as `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AFC2rsTqyN_P"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "_m43xXuZe366"
   },
   "outputs": [],
   "source": [
    "# load the data into our data frame\n",
    "data_url = 'https://raw.githubusercontent.com/PaulHancock/COMP5009_pracs/main/data/arrhythmia.data.with.header.csv'\n",
    "df = pd.read_csv(data_url, na_values = '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ja8VH3vNyYEV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>att10</th>\n",
       "      <th>...</th>\n",
       "      <th>att271</th>\n",
       "      <th>att272</th>\n",
       "      <th>att273</th>\n",
       "      <th>att274</th>\n",
       "      <th>att275</th>\n",
       "      <th>att276</th>\n",
       "      <th>att277</th>\n",
       "      <th>att278</th>\n",
       "      <th>att279</th>\n",
       "      <th>att280</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>91</td>\n",
       "      <td>193</td>\n",
       "      <td>371</td>\n",
       "      <td>174</td>\n",
       "      <td>121</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>49.4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64</td>\n",
       "      <td>81</td>\n",
       "      <td>174</td>\n",
       "      <td>401</td>\n",
       "      <td>149</td>\n",
       "      <td>39</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>20.4</td>\n",
       "      <td>38.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>95</td>\n",
       "      <td>138</td>\n",
       "      <td>163</td>\n",
       "      <td>386</td>\n",
       "      <td>185</td>\n",
       "      <td>102</td>\n",
       "      <td>96</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>175</td>\n",
       "      <td>94</td>\n",
       "      <td>100</td>\n",
       "      <td>202</td>\n",
       "      <td>380</td>\n",
       "      <td>179</td>\n",
       "      <td>143</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.2</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>34.6</td>\n",
       "      <td>61.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>80</td>\n",
       "      <td>88</td>\n",
       "      <td>181</td>\n",
       "      <td>360</td>\n",
       "      <td>177</td>\n",
       "      <td>103</td>\n",
       "      <td>-16</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>62.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 280 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   att1  att2  att3  att4  att5  att6  att7  att8  att9  att10  ...  att271  \\\n",
       "0    75     0   190    80    91   193   371   174   121    -16  ...     0.0   \n",
       "1    56     1   165    64    81   174   401   149    39     25  ...     0.0   \n",
       "2    54     0   172    95   138   163   386   185   102     96  ...     0.0   \n",
       "3    55     0   175    94   100   202   380   179   143     28  ...     0.0   \n",
       "4    75     0   190    80    88   181   360   177   103    -16  ...     0.0   \n",
       "\n",
       "   att272  att273  att274  att275  att276  att277  att278  att279  att280  \n",
       "0     9.0    -0.9     0.0       0     0.9     2.9    23.3    49.4       8  \n",
       "1     8.5     0.0     0.0       0     0.2     2.1    20.4    38.8       6  \n",
       "2     9.5    -2.4     0.0       0     0.3     3.4    12.3    49.0      10  \n",
       "3    12.2    -2.2     0.0       0     0.4     2.6    34.6    61.6       1  \n",
       "4    13.1    -3.6     0.0       0    -0.1     3.9    25.4    62.8       7  \n",
       "\n",
       "[5 rows x 280 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3NHgyIh6dy_5"
   },
   "source": [
    "### Modify att280\n",
    "Modify the values of the class attribute att280 as follows:\n",
    "\n",
    "a. Convert value 1 to N\n",
    "\n",
    "b. Convert value 16 to O\n",
    "\n",
    "c. Convert other values to A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IH04qsxueVL9"
   },
   "source": [
    "Note that pandas has imported this column as a numerical type, but we are going to convert it into a string (object) type. Lets do this by making a new column of type object (single character strings), whith the values N, O, or A as indicated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sdi5WbFOyHgo"
   },
   "source": [
    "An easy way of creating a new column (or Series as in the Pandas terminology) is to just copy and existing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jOewW2EjbgkE"
   },
   "outputs": [],
   "source": [
    "# Create a copy so that we don't try to edit the original\n",
    "new_col = df['att280'].copy()\n",
    "# we use the mask function to replace values inplace. Note that this will convert the series to type object.\n",
    "new_col.mask(df['att280'] == 1,\n",
    "             other='N',\n",
    "             inplace=True)\n",
    "# now do the same for O and A\n",
    "new_col.mask ?\n",
    "\n",
    "new_col.mask ?\n",
    "\n",
    "# we now replace the existing column with our new series.\n",
    "df['att280'] = new_col\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iFep6rzh122n"
   },
   "source": [
    "### Remove attributes\n",
    "Find and remove all attributes with more than 80% missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-xxQSfU1-AN"
   },
   "source": [
    "Finding the attributes with >80% missing values should be easy since we created a function for this last week. Lets copy that function and reuse it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GdCzU_hqygp1"
   },
   "outputs": [],
   "source": [
    "# Function from last week - copy and paste the function here\n",
    "def n_missing(df):\n",
    "    \n",
    "  \"\"\"\n",
    "  For each attribute/column in the dataframe `df`, count the number of missing entries.\n",
    "  Print the attribute name and the number/fraction of blank entries in the following format:\n",
    "  <Colname> has <missing>/<total> blank entries (<frac>%)\n",
    "  \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zUnjdYQc40l7"
   },
   "outputs": [],
   "source": [
    "n_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AO-If4uI2P94"
   },
   "source": [
    "Deleting the columns can be done with the `.drop()` function, we just need a list of columns to remove."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oD_4w27v2XZO"
   },
   "outputs": [],
   "source": [
    "# figure out which columns you want to drop from above, and put their names in the list below\n",
    "cols_to_drop = []\n",
    "df.drop(columns=cols_to_drop,\n",
    "        inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2vr5IkD3tbt"
   },
   "outputs": [],
   "source": [
    "# confirm that our data frame now has fewere columns\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c6tWiY1m4qEe"
   },
   "source": [
    "### Replace missing values\n",
    "Find all attributes with less than 5% missing values and replace these missing values with either the mean or the mode of the attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbZ6j8id3k9w"
   },
   "outputs": [],
   "source": [
    "n_missing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AC1Bwv-444Ya"
   },
   "source": [
    "Look at the `fillna()` function for ways to replace the `NaN` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M_gRPSCs5D7k"
   },
   "outputs": [],
   "source": [
    "# compute the mean\n",
    "mean = df['att14'].mean()\n",
    "# now use the fillna function to replace the NaN avalues with the mean value\n",
    "df['att14'].fillna ?\n",
    "# check that the replacement has worked.\n",
    "df['att14'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCZ7iOHp7cWb"
   },
   "source": [
    "### Discritize attributes\n",
    "Discretize attributes att3 and att4 into 10 equi-width ranges and 10 equi-depth ranges respectively. \n",
    "\n",
    "a. Examine and comment on the intervals in each case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9s0YiUlABy33"
   },
   "source": [
    "First lets get a summary of the attributes so that we can see what we are dealing with here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9n1G4tXPBt7v"
   },
   "outputs": [],
   "source": [
    "# note that the index is now a list of attribute names\n",
    "df[['att3', 'att4']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WHJLyaJ7mYR"
   },
   "source": [
    "Look at the documentation for `qcut` and `cut` for help with this one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMfDr4755FhV"
   },
   "outputs": [],
   "source": [
    "# use cut to create equal width bins\n",
    "results, bins = pd.cut\n",
    "print(results.value_counts(sort=False))\n",
    "print(bins)\n",
    "att3_10_equi_width = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jYvxhcfZ7yaM"
   },
   "outputs": [],
   "source": [
    "# plot a histogram of the equiwidth data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2YmFp76H-BDJ"
   },
   "outputs": [],
   "source": [
    "# now use qcut to create equal depth bins (or at least try)\n",
    "results, bins = pd.qcut\n",
    "print(results.value_counts(sort=False))\n",
    "print(bins)\n",
    "att3_10_equi_depth = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2x_tIw4K8uX7"
   },
   "outputs": [],
   "source": [
    "# plot a histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SrHTWTDaCH4K"
   },
   "source": [
    "### Standardise numeric attributes\n",
    "Standardize all numeric attributes to a mean of 0 and a standard deviation of 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDBI76n7COrC"
   },
   "source": [
    "So for each atttribute compute the mean ($\\mu$) and the standard deviation ($\\sigma$) and then replace the values with $z= \\frac{x-\\mu}{\\sigma}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MBE3LQQICOCi"
   },
   "outputs": [],
   "source": [
    "# example for one column, use this to create a loop that will apply this to all numeric columns\n",
    "new_col = (df['att5'] - df['att5'].mean()) / df['att5'].std()\n",
    "# check that the mean is 0 and std is 1\n",
    "new_col.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMXKr5aPC8oa"
   },
   "source": [
    "### Detect and remove duplicates\n",
    "Detect all duplicate rows and remove them if found.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1nW1IV6oDv8V"
   },
   "source": [
    "Look at `duplicated` as a starting point. Try to show all duplicates (the ones that we will remove)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mNlxj3MlCr5J"
   },
   "outputs": [],
   "source": [
    "dups = df.duplicated()\n",
    "dups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lUQzkhkEDwl"
   },
   "source": [
    "Removing duplicate rows can be done either by noting the index of the duplicates above and feeding that into the `drop()` function, or by using the `drop_duplicates()` function which combines the finding and dropping together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ugkk5-NDEuH"
   },
   "outputs": [],
   "source": [
    "# using ~dups we are indexing on all rows of dups that are false (ie not duplicates)\n",
    "df[~ dups]\n",
    "\n",
    "# lets use drop_duplicates() to remove the duplicate rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MmRVqFBhEfFK"
   },
   "source": [
    "### Random sampling\n",
    "Randomly sample 100 instances and save them as `test.csv`. Save the remaining instances as `train.csv` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVmpegtzGkfJ"
   },
   "source": [
    "Look at `sample` to generate a random selection of rows/instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y22r0aJaEljd"
   },
   "outputs": [],
   "source": [
    "test = df.sample\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VJKcY5UrGqru"
   },
   "source": [
    "Now the inverse problem. Not so easy as there is no pandas function that will directly give us the inverse of the above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2DYnYCUnGQrt"
   },
   "outputs": [],
   "source": [
    "train = \n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gbZHKwx8Hf-6"
   },
   "source": [
    "And we save these to a `.csv` file using the `save_csv` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F-K-R6CxHfkT"
   },
   "outputs": [],
   "source": [
    "test.to_csv('test.csv')\n",
    "train.to_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SYBEcOccHyeX"
   },
   "source": [
    "Look in the current directory to see these files and download them. On the left panel click the file explorer to see the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHOOeexZH_RJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIH1yANcIdr-"
   },
   "source": [
    "## Q13 from Chapter 3 of [Aggarwal](https://www.springer.com/gp/book/9783319141411)\n",
    "\n",
    "Use the modified KDD Cup 1999 data set provided as `kddcup.csv` and specifically examine attribute `count`. \n",
    "\n",
    "1. The data are available via github as [kddcup.arff](https://raw.githubusercontent.com/PaulHancock/COMP5009_pracs/main/data/kddcup99.arff), load them as a pandas data frame\n",
    "\n",
    "1. Compute the average µ and standard deviation σ of this attribute over 10,000 samples. \n",
    "\n",
    "1. Randomly select a subset of n samples from this data set with \n",
    "  n = 10; 20; 50; 100; 200; 500; 1000; 2000; 5000; 10000: \n",
    "\n",
    "  For each value of n compute the average $e_n$ of the attribute over the subset and then derive the following quantity: \n",
    "\n",
    "  $z_n=\\frac{|e_n-\\mu|}{\\sigma}$\n",
    "\n",
    "  You should repeat this at least 10 times and obtain the average of zn. \n",
    "\n",
    "1. Plot $z_n$ versus n and make a comment on the graph you have plotted. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IPg_AA3-xrYE"
   },
   "source": [
    "### Load the data\n",
    "\n",
    "The data are available via github as [kddcup.csv](https://raw.githubusercontent.com/PaulHancock/COMP5009_pracs/main/data/kddcup99.arff), load them as a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UERaE2hQpy6Q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# This time the file is in arff format so we need a library that can read it\n",
    "from scipy.io import arff\n",
    "import urllib\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5w_ii-GAsY5N"
   },
   "source": [
    "The file that we are working with is in `arff` format, which can't be read directly by pandas. Instead we use an arff loader from `scipy.io`, but we must first download the file before we can open it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PgxH9WQqspht"
   },
   "outputs": [],
   "source": [
    "data_url = 'https://raw.githubusercontent.com/PaulHancock/COMP5009_pracs/main/data/kddcup99.arff'\n",
    "file_name = 'kddcup99.arff'\n",
    "# this will download the file, look in your explorer to confirm\n",
    "urllib.request.urlretrieve(data_url, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qgh_Jwx2p9LG"
   },
   "outputs": [],
   "source": [
    "# load the data from arff format\n",
    "data = arff.loadarff(file_name)\n",
    "df = pd.DataFrame(data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6X0Faqos8kk"
   },
   "source": [
    "### Compute $\\mu$ and $\\sigma$\n",
    "Compute the average µ and standard deviation σ of this attribute over 10,000 samples. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "il_DF_NDqE8G"
   },
   "outputs": [],
   "source": [
    "mu = \n",
    "sigma = \n",
    "print(f\"For attribute `count`: μ={mu:.2f}, σ={sigma:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVEIuyqlthfI"
   },
   "source": [
    "### Random subsets\n",
    "Randomly select a subset of n samples from this data set with \n",
    "  n = 10; 20; 50; 100; 200; 500; 1000; 2000; 5000; 10000: \n",
    "\n",
    "  For each value of n compute the average $e_n$ of the attribute over the subset and then derive the following quantity: \n",
    "\n",
    "  $z_n=\\frac{|e_n-\\mu|}{\\sigma}$\n",
    "\n",
    "  You should repeat this at least 10 times and obtain the average of zn. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3idqm5HtyiZ"
   },
   "outputs": [],
   "source": [
    "x = [10,20,50,100,200,1_000,2_000,5_000,10_000]\n",
    "y = []\n",
    "for n in x:\n",
    "  # append to z for 10 iterations\n",
    "  z = []\n",
    "  for _ in range(10):\n",
    "    # compute e_n, and then z\n",
    "    en = \n",
    "    z.append(?)\n",
    "  # compute the mean and append to y\n",
    "  zn = np.mean(z)\n",
    "  y.append(zn)\n",
    "  print(f'n={n}, zn={zn}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QAxORIq0xCrW"
   },
   "source": [
    "### Plot $z_n$\n",
    "Plot $z_n$ versus n and make a comment on the graph you have plotted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2jWnCg_xOEW"
   },
   "source": [
    "Let's use matplotlib directly for our plotting this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "htswyvPmuK64"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P1bRFvWfvE6Z"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "ax.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L4RbOqgVxSgu"
   },
   "source": [
    "What do we observe in the above?\n",
    "\n",
    "Hint: try a log scale for the axes."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "cqWJd87HcgLF",
    "zIH1yANcIdr-",
    "IPg_AA3-xrYE",
    "T6X0Faqos8kk",
    "oVEIuyqlthfI",
    "QAxORIq0xCrW"
   ],
   "name": "PracB_DataPreparation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
