{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUQE3Da1tUd7"
   },
   "source": [
    "# Supermarket basket association pattern mining\n",
    "\n",
    "In this question, we perform association pattern mining using the supermarket dataset `supermarket.arff` from the [Weka MOOC](https://www.cs.waikato.ac.nz/ml/weka/courses.html).\n",
    "\n",
    "\n",
    "1. Load the data file `supermarket.arff` into a pandas data frame\n",
    "\n",
    "2. Remove the following attributes \n",
    "  - Department* \n",
    "  - non host support \n",
    "  - Total \n",
    "\n",
    "3.  Select the Apriori algorithm and perform frequent itemset mining with minsup = 0.2 and minconf = 0.8 and find out: \n",
    "  - The numbers of frequent 2-itemsets, and 3-itemsets. \n",
    "  - The best three (2) rules with largest confidence. Examine these rules and describe them in your own words. \n",
    "\n",
    "4. The supermarket manager wishes to boost the sale of fruit and therefore the manager needs to know other itemsets most likely be purchased with fruit to make promotion decisions. \n",
    "  - Using the same minimum support and minimum confidence value. \n",
    "  - List the top three itemsets to report to the supermarket manager. \n",
    "\n",
    "5. Repeat task 3, but using the FP Growth algorithm instead.  \n",
    "  - Compare the rules found. \n",
    "  - Are they consistent? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sesbe9KEL5tx"
   },
   "source": [
    "## 0 Upgrade mlxtend\n",
    "The default version of `mlxtend` on Google Colaborate is too old for this prac\n",
    "so we must upgrade it. We want something that is at least version 0.18.\n",
    "Note that code statements beginning with `!` are not python code, but system calls. If you are running this in a personal jupyterlab you might have to update this module a different way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aFBB2RsZf79_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting mlxtend>=0.18\n",
      "  Downloading mlxtend-0.18.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.2 in /Library/Python/3.8/site-packages (from mlxtend>=0.18) (1.20.2)\n",
      "Collecting pandas>=0.24.2\n",
      "  Downloading pandas-1.3.2-cp38-cp38-macosx_10_9_x86_64.whl (11.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.4 MB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.13.2\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib>=3.0.0\n",
      "  Downloading matplotlib-3.4.3-cp38-cp38-macosx_10_9_x86_64.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scikit-learn>=0.20.3\n",
      "  Downloading scikit_learn-0.24.2-cp38-cp38-macosx_10_13_x86_64.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 5.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from mlxtend>=0.18) (41.2.0)\n",
      "Collecting scipy>=1.2.1\n",
      "  Downloading scipy-1.7.1-cp38-cp38-macosx_10_9_x86_64.whl (32.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 32.6 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.2.1 in /Library/Python/3.8/site-packages (from matplotlib>=3.0.0->mlxtend>=0.18) (2.4.7)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp38-cp38-macosx_10_9_x86_64.whl (61 kB)\n",
      "\u001b[K     |████████████████████████████████| 61 kB 455 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.3.1-cp38-cp38-macosx_10_10_x86_64.whl (2.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.9 MB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /Library/Python/3.8/site-packages (from matplotlib>=3.0.0->mlxtend>=0.18) (2.8.1)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: six in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.8/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=3.0.0->mlxtend>=0.18) (1.15.0)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 6.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, pytz, pillow, kiwisolver, joblib, cycler, scikit-learn, pandas, matplotlib, mlxtend\n",
      "Successfully installed cycler-0.10.0 joblib-1.0.1 kiwisolver-1.3.1 matplotlib-3.4.3 mlxtend-0.18.0 pandas-1.3.2 pillow-8.3.1 pytz-2021.1 scikit-learn-0.24.2 scipy-1.7.1 threadpoolctl-2.2.0\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip install --upgrade 'mlxtend>=0.18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uYe47OJWf8h0"
   },
   "outputs": [],
   "source": [
    "# Check we have the right version\n",
    "import mlxtend\n",
    "print(mlxtend.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N4nbxT6vtBd9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "import urllib\n",
    "import urllib.request\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l-jloVtsMriH"
   },
   "source": [
    "## 1 Load the data file `supermarket.arff` into a pandas data frame\n",
    "\n",
    "We did this in a previous prac: download the file into your working directory using `urrlib`, load it using `scipy`, and then convert to a `pandas` data frame. The file on the Weka website has a few problems that we need to work around, so I've provided a cleaned version of the data on [GitHub](https://raw.githubusercontent.com/PaulHancock/COMP5009_pracs/main/data/supermarket.arff)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lHP3pP7ms034"
   },
   "outputs": [],
   "source": [
    "data_url = 'https://raw.githubusercontent.com/PaulHancock/COMP5009_pracs/main/data/supermarket.arff'\n",
    "file_name = 'supermarket.arff'\n",
    "urllib.request.urlretrieve(data_url, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkG2OE8ptOtk"
   },
   "outputs": [],
   "source": [
    "# load the data from arff format\n",
    "data = arff.loadarff('supermarket.arff')\n",
    "raw_df = pd.DataFrame(data[0])\n",
    "# The data table is 1 and 0, but we want it to be boolean (true/false) so we convert\n",
    "df = raw_df.astype(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Wbo3P65tRfR"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A-i7Z3PwQkiB"
   },
   "source": [
    "## 2 Remove attributes \n",
    "Remove the following attributes as they have been deemed to be not-useful:\n",
    "  - Department* \n",
    "  - non host support \n",
    "  - Total \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zz4kpMryQwcv"
   },
   "outputs": [],
   "source": [
    "cols_to_drop = ['non host support', 'total']\n",
    "# Instead of hand writing all the names that start with department, use a loop\n",
    "for col in df.columns:\n",
    "  if col.startswith(?):\n",
    "    cols_to_drop.append(col)\n",
    "print(\"The folloiwing columns will be dropped:\")\n",
    "print(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qDaU8qX_RSVN"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2cp1xD1RaPr"
   },
   "outputs": [],
   "source": [
    "# confirm we have dropped the columns by showing a summary, we should have 104 cols left, all with descriptive names.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ND5nK5G2Rq1i"
   },
   "source": [
    "## 3 Select the Apriori algorithm \n",
    "\n",
    "Select the Apriori algorithm and perform frequent itemset mining with `minsup = 0.2` and `minconf = 0.8` and find out:\n",
    "\n",
    "- The numbers of frequent 2-itemsets, and 3-itemsets.\n",
    "- The best three rules with largest confidence. Examine these rules and describe them in your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_wQ33C0R4G_"
   },
   "source": [
    "The `apriori` algorithm is found in the `mlxtend` package, so we import it along with the `association_rules` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bc2QfjzYtrca"
   },
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import apriori, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HH8DMnP0ve2r"
   },
   "outputs": [],
   "source": [
    "ap_itemsets = apriori(df, \n",
    "                      min_support=?,\n",
    "                      use_colnames=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXljuPEcWMrY"
   },
   "source": [
    "Now that we have our itemsets we want to chose those with `2<=k<=3`.\n",
    "This isn't explicitly stored within our dataframe so we'll make a new column which is just the value of `len(itemsets)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_g6y3hvZYqIj"
   },
   "outputs": [],
   "source": [
    "def find_k(row):\n",
    "  \"\"\"Return the number of items in the itemset\"\"\"\n",
    "  return len(row.itemsets)\n",
    "\n",
    "# Create a new column which counts the number of items in the itemset\n",
    "ap_itemsets['k'] = ap_itemsets.apply(find_k, # Apply the function `find_k`\n",
    "                                     axis=1) # apply the function to each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x2Ksn907Wa7L"
   },
   "outputs": [],
   "source": [
    "k2_itemsets = np.sum(ap_itemsets['k'] == 2)\n",
    "k3_itemsets = np.sum(ap_itemsets['k'] == 3)\n",
    "print(f\"There are {k2_itemsets} itemsets with k=2\")\n",
    "print(f\"There are {k3_itemsets} itemsets with k=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ijC8V8UfLFZ6"
   },
   "outputs": [],
   "source": [
    "# Now lets see the top 10 itemsets\n",
    "ap_itemsets.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZMcj28c4LQkz"
   },
   "source": [
    "Note that the top 10 itemsets are all 1-itemsets. Is this surprising to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndL2KS9eSsUM"
   },
   "source": [
    "We use these itemsets to generate association rules with a minimum confidence of 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ii2jSPGsvoms"
   },
   "outputs": [],
   "source": [
    "ap_rules = association_rules(ap_itemsets, \n",
    "                             metric='confidence', \n",
    "                             min_threshold=?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3wmmvgHB4ywa"
   },
   "outputs": [],
   "source": [
    "ap_rules.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69xFyGBlTL1u"
   },
   "source": [
    "Note that the rules above are not sorted by confidence. We should do that ourselves by using the `sort_values` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KflkW0vSS_J3"
   },
   "outputs": [],
   "source": [
    "ap_rules.sort_values('confidence', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_yT94ofTaA8"
   },
   "source": [
    "Now describe the first three that you see above in your own words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHyYiku2TpdG"
   },
   "source": [
    "## 4 Boost fruit sales\n",
    "The supermarket manager wishes to boost the sale of fruit and therefore the manager needs to know other itemsets most likely be purchased with fruit to make promotion decisions. \n",
    "  - Using the same minimum support and minimum confidence value. \n",
    "  - List the top three itemsets to report to the supermarket manager. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXHZ-iF-MBqQ"
   },
   "outputs": [],
   "source": [
    "# choose all the rules wihch have \"fruit\" (not canned fruit) as the consquent\n",
    "fruit_rules = ap_rules[ap_rules.consequents == frozenset([?])]\n",
    "# now sort based on confidence and report the top 3\n",
    "fruit_rules.sort_values(?,\n",
    "                        ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqG1xep9OuZ7"
   },
   "source": [
    "## 5 FP-Growth\n",
    "Repeat task 3, but using the FP Growth algorithm instead.  \n",
    "  - Compare the rules found. \n",
    "  - Are they consistent? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlhJDkJlPA5l"
   },
   "source": [
    "Import the `fpgrowth` function from our `mlxtend` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ksp_hczq0EgW"
   },
   "outputs": [],
   "source": [
    "from mlxtend.frequent_patterns import fpgrowth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_RrIK42Ve_Xv"
   },
   "outputs": [],
   "source": [
    "fp_itemsets = fpgrowth(df,\n",
    "                       min_support=?,\n",
    "                       use_colnames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "942LR6AhgYOt"
   },
   "outputs": [],
   "source": [
    "fp_rules = association_rules(fp_itemsets, \n",
    "                             metric='confidence', \n",
    "                             min_threshold=?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDcUV0QhPMdA"
   },
   "source": [
    "There are a lot of rules, lets compare just the first 10 most confident rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eSeodYelhckj"
   },
   "outputs": [],
   "source": [
    "# Select the top 10 confident rules from each of our algorithms\n",
    "fp_top_10 = fp_rules.sort_values('confidence', ascending=False).head(10)\n",
    "ap_top_10 = ap_rules.sort_values('confidence', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "McBW4hh_hfMB"
   },
   "outputs": [],
   "source": [
    "print(\"FP-Growth rules\")\n",
    "fp_top_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVPqi8T6RqjT"
   },
   "outputs": [],
   "source": [
    "print(\"Apriori rules\")\n",
    "ap_top_10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xycAJ2gKR0GJ"
   },
   "source": [
    "Do the above tables agree?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PracD_AssociationPatternMining.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
